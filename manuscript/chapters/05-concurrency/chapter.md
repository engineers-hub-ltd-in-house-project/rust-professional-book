# 第5章: 恐れることのない並行性

## 学習目標
本章を修了すると、以下が可能になります：
- [ ] データ競合とは何かを理解し、なぜそれが危険なのかを説明できる。
- [ ] `Mutex`と`Arc`を使い、スレッド間で安全に状態を共有できる。
- [ ] `Send`と`Sync`トレイトが、Rustの並行性の安全性をいかにコンパイル時に保証しているかを説明できる。
- [ ] メッセージパッシング（チャネル）を、状態共有の代替案として利用できる。
- [ ] `rayon`クレートを使い、データ並列処理を驚くほど簡単に行える。

---

## 5.1 導入：なぜ並行プログラミングは難しいのか？

現代のCPUは複数のコアを持つのが当たり前になり、性能を最大限に引き出すには、複数の処理を同時に実行する「並行プログラミング」が不可欠です。しかし、多くの言語において、並行プログラミングはバグの温床でした。

- **データ競合 (Data Race):** 複数のスレッドが同じデータに同時にアクセスし、少なくとも一つのスレッドが書き込みを行うことで、データが予期せず破壊される状態。結果はタイミングに依存し、再現が極めて困難。
- **デッドロック (Deadlock):** 二つ以上のスレッドが、互いが保持しているリソースを要求し、永遠に待ち続ける状態。

これらの問題は、長年プログラマを苦しめてきました。Rustの目標は、これらの問題をコンパイル時に検出し、実行時には発生し得ないようにすることで、開発者が「恐れることなく」並行コードを書けるようにすることです。本章では、そのための実践的なツールと思想を学びます。

---

## 5.2 問題の可視化：データ競合

まず、データ競合が実際にどのような問題を引き起こすかを見てみましょう。単純なカウンターを複数のスレッドでインクリメントするプログラムです。

```rust
use std::thread;

fn main() {
    let mut counter = 0;

    let mut handles = vec![];

    for _ in 0..10 {
        // counterの所有権がムーブしてしまうため、このコードはコンパイルできない
        // let handle = thread::spawn(move || {
        //     for _ in 0..1000 {
        //         counter += 1;
        //     }
        // });
        // handles.push(handle);
    }

    // ...
}
```

このコードは、所有権のルールによりそもそもコンパイルできません。仮にコンパイルできたとしても、`counter += 1`という操作はアトミック（不可分）ではありません。「(1)値を読み込む、(2)1を加える、(3)値を書き込む」という3ステップの間に他のスレッドが割り込む可能性があり、最終的な結果は期待する`10000`にはならず、実行するたびに変わってしまいます。

---

## 5.3 解決策① 状態の共有：`Mutex` と `Arc`

この問題を解決する最も古典的な方法は、データへのアクセスを一度に一つのスレッドに限定することです。そのためのツールが**`Mutex<T>` (Mutual Exclusion)**です。

`Mutex`は、内部のデータ`T`へのアクセスに`lock()`を要求します。`lock()`が成功すると、他のスレッドは`lock()`でブロックされ、待機状態になります。ロックを獲得したスレッドが`MutexGuard`（`lock()`の返り値）を解放すると、待っていた別のスレッドがロックを獲得できます。

```rust
use std::sync::Mutex;

let m = Mutex::new(5);

{
    let mut num = m.lock().unwrap(); // ロックを獲得。他のスレッドはここで待つ
    *num = 6;
} // MutexGuard `num`がスコープを抜けるときに自動的にロックが解放される
```

では、この`Mutex`を複数のスレッドで共有するにはどうすればよいでしょうか？ここで登場するのが**`Arc<T>` (Atomically Reference Counted)**です。
`Arc`は、第2章で学んだ`Rc`のスレッドセーフ版です。所有者の数をアトミックに（スレッドセーフに）カウントすることで、複数のスレッドが同じデータへの所有権を共有できるようにします。

これらを組み合わせた`Arc<Mutex<T>>`は、Rustにおけるスレッドセーフな状態共有の最も重要なイディオムです。

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // Arc<Mutex<T>> パターンでカウンターをスレッドセーフにする
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter_clone = Arc::clone(&counter); // 参照カウントをインクリメント
        let handle = thread::spawn(move || {
            let mut num = counter_clone.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap()); // 10
}
```
このコードは、データ競合を起こすことなく、常に期待通りの結果を返します。

---

## 5.4 安全性の根拠：`Send` と `Sync` トレイト

なぜ`Rc`はスレッド間で共有できず、`Arc`はできるのでしょうか？なぜ`Mutex`は安全なのでしょうか？その答えは、**`Send`**と**`Sync`**という二つのマーカートレイトにあります。

- **`Send`トレイト:** ある型の値の**所有権**を、スレッド間で安全に移動できることを示します。`i32`, `String`, `Vec<T>` (TがSendの場合), `Arc<T>` (TがSend+Syncの場合) など、多くの型が`Send`を実装しています。しかし、`Rc<T>`は参照カウントの操作がアトミックでないため、`Send`ではありません。

- **`Sync`トレイト:** ある型の値への**共有参照 (`&T`)** を、複数のスレッドから同時にアクセスしても安全であることを示します。`&i32`, `&str`, `Arc<T>` (TがSend+Syncの場合) などは`Sync`です。しかし、`RefCell<T>`や`Cell<T>`のような内部可変性を持つ型は、ロック機構なしでのアクセスは競合を起こすため`Sync`ではありません。

`Mutex<T>`は、内部のロック機構によって`&Mutex<T>`を通じたアクセスを保護するため、`Sync`です。これにより、複数のスレッドが`&Arc<Mutex<T>>`を安全に共有できるのです。

重要なのは、これらのトレイト境界を**コンパイラが強制する**という点です。`Send`でない値をスレッドに渡そうとすると、コンパイルエラーになります。これにより、データ競合の可能性のあるコードは、そもそも実行ファイルにすらならないのです。これこそが「恐れることのない並行性」の源泉です。

---

## 5.5 解決策② メッセージパッシング

状態を共有する代わりに、「アクターは孤立しており、互いにメッセージを送り合うことで通信する」という考え方もあります。これは、ロックに伴う複雑さやデッドロックの可能性を減らすことができる、強力な設計パターンです。

Rustの標準ライブラリは、`std::sync::mpsc`モジュールで**チャネル**を提供しています。`mpsc`は「Multiple Producer, Single Consumer」の略で、複数の送信側と一つの受信側を持つことができます。

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel(); // 送信機(tx)と受信機(rx)を作成

    let tx_clone = tx.clone();

    // スレッド1: メッセージを送信
    thread::spawn(move || {
        let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
        ];
        for val in vals {
            tx.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    // スレッド2: こちらもメッセージを送信
    thread::spawn(move || {
        let vals = vec![
            String::from("more"),
            String::from("messages"),
            String::from("for"),
            String::from("you"),
        ];
        for val in vals {
            tx_clone.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    // メインスレッドでメッセージを受信して表示
    for received in rx {
        println!("Got: {}", received);
    }
}
```

このモデルでは、データ（`String`）の所有権が送信時に`send`関数にムーブされ、受信側がそれを受け取ります。どの瞬間においてもデータの所有者は一人だけなので、ロックは不要です。

---

## 5.6 簡単な並列処理：`rayon` クレート

最後に、並行（concurrency）と並列（parallelism）の違いを意識しましょう。
- **並行:** 複数のタスクを管理し、切り替えながら進めること（必ずしも同時に実行されるとは限らない）。
- **並列:** 複数のタスクを物理的に同時に実行すること（マルチコアCPUが必要）。

データ処理タスクを簡単に並列化し、CPUコアを使い切ってパフォーマンスを向上させたい場合、**`rayon`**クレートが驚くほど効果的です。

`rayon`は、データ並列処理のイディオムを提供します。最も強力な機能は、標準ライブラリのイテレータを並列版に置き換える`par_iter()`です。

```rust
// 依存関係を Cargo.toml に追加: rayon = "1.5"
use rayon::prelude::*;

fn sum_of_squares(input: &[i32]) -> i32 {
    input.iter().map(|&i| i * i).sum()
}

fn parallel_sum_of_squares(input: &[i32]) -> i32 {
    // .iter() を .par_iter() に変えるだけ！
    input.par_iter().map(|&i| i * i).sum()
}
```

たったこれだけの変更で、`rayon`は内部的に**ワークスティーリング**という高度なスケジューリングアルゴリズムを使い、配列の処理を複数のスレッドに効率的に分割し、自動的に並列実行してくれます。CPUバウンドな計算（純粋な計算処理）では、これによりコア数に比例した劇的なパフォーマンス向上が得られます。

---

## 5.7 まとめ

本章では、Rustで安全に並行・並列コードを書くための、実践的で重要な3つのアプローチを学びました。

1.  **共有メモリ (`Arc<Mutex<T>>`):** 複数のスレッド間で状態を共有するための、基本的で強力なパターン。
2.  **メッセージパッシング (`mpsc::channel`):** ロックを避け、所有権の移動によって通信するクリーンな設計。
3.  **データ並列 (`rayon`):** CPUバウンドな問題を、最小限のコード変更で劇的に高速化する手段。

そして、これら全てを支えているのが、コンパイル時にデータ競合を防ぐ**`Send`と`Sync`トレイト**です。これにより、Rust開発者は実行時エラーの恐怖から解放され、自信を持ってマルチコアの性能を最大限に引き出すことができるのです。