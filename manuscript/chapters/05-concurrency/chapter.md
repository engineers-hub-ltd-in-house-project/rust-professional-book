---
part: "第II部: 実装パターン編"
page_count: 40
title: "並行性理論とRustの実装"
---

# 第5章: 恐れることのない並行性

## 学習目標
この章を読み終えると、以下ができるようになります：
- [ ] データ競合とは何かを理解し、なぜそれが危険なのかを説明できる。
- [ ] `Mutex`と`Arc`を使い、スレッド間で安全に状態を共有できる。
- [ ] `Send`と`Sync`トレイトが、Rustの並行性の安全性をいかにコンパイル時に保証しているかを説明できる。
- [ ] メッセージパッシング（チャネル）を、状態共有の代替案として利用できる。
- [ ] `rayon`クレートを使い、データ並列処理を驚くほど簡単に行える。

---

## 5.1 導入：なぜ並行プログラミングは難しいのか？

現代のCPUは複数のコアを持つのが当たり前になり、性能を最大限に引き出すには、複数の処理を同時に実行する「並行プログラミング」が不可欠です。しかし、多くの言語において、並行プログラミングはバグの温床でした。

**CSのポイント:** 並行プログラミングは、CSの**「並列計算」**や**「分散システム」**における最も複雑でデバッグが困難な領域の一つです。複数の実行主体（スレッド、プロセス）が時間的に重なって動作することで、以下のような問題が発生します。

- **データ競合 (Data Race):** 複数のスレッドが同じデータに同時にアクセスし、少なくとも一つのスレッドが書き込みを行うことで、データが予期せず破壊される状態。結果はタイミングに依存し、再現が極めて困難。
- **デッドロック (Deadlock):** 二つ以上のスレッドが、互いが保持しているリソースを要求し、永遠に待ち続ける状態。
- **ライブロック (Livelock):** スレッドが互いに状態を変化させ続けるが、進行がない状態。
- **飢餓 (Starvation):** 特定のスレッドが、リソースを獲得できずに永遠に実行できない状態。

これらの問題は、長年プログラマを苦しめてきました。Rustの目標は、これらの問題をコンパイル時に検出し、実行時には発生し得ないようにすることで、開発者が「恐れることなく」並行コードを書けるようにすることです。本章では、そのための実践的なツールと思想を学びます。

---

## 5.2 問題の可視化：データ競合

まず、データ競合が実際にどのような問題を引き起こすかを見てみましょう。単純なカウンターを複数のスレッドでインクリメントするプログラムです。

```rust
use std::thread;

fn main() {
    let mut counter = 0;

    let mut handles = vec![];

    for _ in 0..10 {
        // counterの所有権がムーブしてしまうため、このコードはコンパイルできない
        // let handle = thread::spawn(move || {
        //     for _ in 0..1000 {
        //         counter += 1;
        //     }
        // });
        // handles.push(handle);
    }

    // ...
}
```

このコードは、所有権のルールによりそもそもコンパイルできません。仮にコンパイルできたとしても、`counter += 1`という操作はアトミック（不可分）ではありません。「(1)値を読み込む、(2)1を加える、(3)値を書き込む」という3ステップの間に他のスレッドが割り込む可能性があり、最終的な結果は期待する`10000`にはならず、実行するたびに変わってしまいます。

**CSのポイント:** `counter += 1`のような操作は、CSの**「クリティカルセクション（Critical Section）」**の典型例です。複数のスレッドが同時にアクセスすると、**「競合状態（Race Condition）」**が発生し、プログラムの正当性が損なわれます。これは、CSの**「並行性制御」**における最も基本的な問題であり、ロックやアトミック操作といった同期メカニズムによって解決されます。

`[図：データ競合の発生メカニズム。2つのスレッドが同時にカウンターをインクリメントしようとし、読み込み、加算、書き込みの各ステップがインターリーブされることで、最終結果が期待値（例：2）ではなく1になる様子をタイムラインで示す。]`

---

## 5.3 解決策① 状態の共有：`Mutex` と `Arc`

この問題を解決する最も古典的な方法は、データへのアクセスを一度に一つのスレッドに限定することです。そのためのツールが**`Mutex<T>` (Mutual Exclusion)**です。

`Mutex`は、内部のデータ`T`へのアクセスに`lock()`を要求します。`lock()`が成功すると、他のスレッドは`lock()`でブロックされ、待機状態になります。ロックを獲得したスレッドが`MutexGuard`（`lock()`の返り値）を解放すると、待っていた別のスレッドがロックを獲得できます。

```rust
use std::sync::Mutex;

let m = Mutex::new(5);

{
    let mut num = m.lock().unwrap(); // ロックを獲得。他のスレッドはここで待つ
    *num = 6;
} // MutexGuard `num`がスコープを抜けるときに自動的にロックが解放される
```

**CSのポイント:** `Mutex`は、CSの**「相互排他（Mutual Exclusion）」**という概念を実装したものです。これは、クリティカルセクションへのアクセスを一度に一つのスレッドに制限することで、データ競合を防ぎ、プログラムの**「正当性」**を保証します。`MutexGuard`がスコープを抜けるときに自動的にロックが解放されるのは、第2章で学んだRAIIパターンの一例です。

では、この`Mutex`を複数のスレッドで共有するにはどうすればよいでしょうか？ここで登場するのが**`Arc<T>` (Atomically Reference Counted)**です。
`Arc`は、第2章で学んだ`Rc`のスレッドセーフ版です。所有者の数をアトミックに（スレッドセーフに）カウントすることで、複数のスレッドが同じデータへの所有権を共有できるようにします。

**CSのポイント:** `Arc`は、CSの**「参照カウント（Reference Counting）」**というメモリ管理手法を、**「アトミック操作（Atomic Operations）」**を用いてスレッドセーフに実装したものです。これにより、複数のスレッドが共有データを安全に参照し、そのライフサイクルを協調して管理できます。

これらを組み合わせた`Arc<Mutex<T>>`は、Rustにおけるスレッドセーフな状態共有の最も重要なイディオムです。

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // Arc<Mutex<T>> パターンでカウンターをスレッドセーフにする
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter_clone = Arc::clone(&counter); // 参照カウントをインクリメント
        let handle = thread::spawn(move || {
            let mut num = counter_clone.lock().unwrap();
            *num += 1;
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap()); // 10
}
```
このコードは、データ競合を起こすことなく、常に期待通りの結果を返します。

`[図：Arc<Mutex<T>>の概念図。複数のスレッドが同じArcポインタを共有し、そのArcがMutexを指し、Mutexが共有データTを保護する様子。ロックがどのようにアクセスを制御するかを示す。]`

---

## 5.4 安全性の根拠：`Send` と `Sync` トレイト

なぜ`Rc`はスレッド間で共有できず、`Arc`はできるのでしょうか？なぜ`Mutex`は安全なのでしょうか？その答えは、**`Send`**と**`Sync`**という二つのマーカートレイトにあります。

**CSのポイント:** `Send`と`Sync`は、Rustの**「型システム」**が並行性の安全性をコンパイル時に保証するための、CSの**「静的解析」**に基づいた強力なメカニズムです。これらのトレイトは、特定の型がスレッド間で安全に移動または共有できるという**「不変条件（Invariants）」**をコンパイラに伝えます。

- **`Send`トレイト:** ある型の値の**所有権**を、スレッド間で安全に移動できることを示します。`i32`, `String`, `Vec<T>` (TがSendの場合), `Arc<T>` (TがSend+Syncの場合) など、多くの型が`Send`を実装しています。しかし、`Rc<T>`は参照カウントの操作がアトミックでないため、`Send`ではありません。`Rc`を`Send`でないスレッドに渡そうとすると、コンパイルエラーになります。

- **`Sync`トレイト:** ある型の値への**共有参照 (`&T`)** を、複数のスレッドから同時にアクセスしても安全であることを示します。`&i32`, `&str`, `Arc<T>` (TがSend+Syncの場合) などは`Sync`です。しかし、`RefCell<T>`や`Cell<T>`のような内部可変性を持つ型は、ロック機構なしでのアクセスは競合を起こすため`Sync`ではありません。`RefCell`への共有参照を複数のスレッドで同時に使おうとすると、コンパイルエラーになります。

`Mutex<T>`は、内部のロック機構によって`&Mutex<T>`を通じたアクセスを保護するため、`Sync`です。これにより、複数のスレッドが`&Arc<Mutex<T>>`を安全に共有できるのです。

重要なのは、これらのトレイト境界を**コンパイラが強制する**という点です。`Send`でない値をスレッドに渡そうとすると、コンパイルエラーになります。これにより、データ競合の可能性のあるコードは、そもそも実行ファイルにすらならないのです。これこそが「恐れることのない並行性」の源泉です。

---

## 5.5 解決策② メッセージパッシング

状態を共有する代わりに、「アクターは孤立しており、互いにメッセージを送り合うことで通信する」という考え方もあります。これは、ロックに伴う複雑さやデッドロックの可能性を減らすことができる、強力な設計パターンです。

**CSのポイント:** メッセージパッシングは、CSの**「アクターモデル（Actor Model）」**や**「CSP（Communicating Sequential Processes）」**といった並行性モデルの根幹をなす概念です。共有メモリによる同期の複雑さを避け、データの所有権をメッセージと共に移動させることで、データ競合を原理的に排除します。

Rustの標準ライブラリは、`std::sync::mpsc`モジュールで**チャネル**を提供しています。`mpsc`は「Multiple Producer, Single Consumer」の略で、複数の送信側と一つの受信側を持つことができます。

```rust
use std::sync::mpsc;
use std::thread;
use std::time::Duration;

fn main() {
    let (tx, rx) = mpsc::channel(); // 送信機(tx)と受信機(rx)を作成

    let tx_clone = tx.clone();

    // スレッド1: メッセージを送信
    thread::spawn(move || {
        let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
        ];
        for val in vals {
            tx.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    // スレッド2: こちらもメッセージを送信
    thread::spawn(move || {
        let vals = vec![
            String::from("more"),
            String::from("messages"),
            String::from("for"),
            String::from("you"),
        ];
        for val in vals {
            tx_clone.send(val).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    // メインスレッドでメッセージを受信して表示
    for received in rx {
        println!("Got: {}", received);
    }
}
```

このモデルでは、データ（`String`）の所有権が送信時に`send`関数にムーブされ、受信側がそれを受け取ります。どの瞬間においてもデータの所有者は一人だけなので、ロックは不要です。

`[図：mpscチャネルを通じたメッセージパッシング。複数の送信者（Producer）がメッセージをチャネルに送り、単一の受信者（Consumer）がそれを受け取る様子。メッセージと共にデータの所有権が移動する様子を示す。]`

---

## 5.6 簡単な並列処理：`rayon` クレート

最後に、並行（concurrency）と並列（parallelism）の違いを意識しましょう。
- **並行 (Concurrency):** 複数のタスクを管理し、切り替えながら進めること（必ずしも同時に実行されるとは限らない）。CSの**「タスクスケジューリング」**や**「仮想並列性」**に関連します。
- **並列 (Parallelism):** 複数のタスクを物理的に同時に実行すること（マルチコアCPUが必要）。CSの**「真の並列性」**や**「マルチコアプログラミング」**に関連します。

データ処理タスクを簡単に並列化し、CPUコアを使い切ってパフォーマンスを向上させたい場合、**`rayon`**クレートが驚くほど効果的です。

`rayon`は、データ並列処理のイディオムを提供します。

```rust
// 依存関係を Cargo.toml に追加: rayon = "1.5"
use rayon::prelude::*;

fn sum_of_squares(input: &[i32]) -> i32 {
    input.iter().map(|&i| i * i).sum()
}

fn parallel_sum_of_squares(input: &[i32]) -> i32 {
    // .iter() を .par_iter() に変えるだけ！
    input.par_iter().map(|&i| i * i).sum()
}
```

**CSのポイント:** `rayon`は、CSの**「データ並列処理」**や**「ワークスティーリング（Work Stealing）」**といった高度な並列アルゴリズムを抽象化しています。ワークスティーリングは、遊んでいるプロセッサが、忙しいプロセッサからタスクを「盗む」ことで、動的な負荷分散を実現し、CPUコアを効率的に使い切ることを可能にします。

たったこれだけの変更で、`rayon`は内部的に**ワークスティーリング**という高度なスケジューリングアルゴリズムを使い、配列の処理を複数のスレッドに効率的に分割し、自動的に並列実行してくれます。CPUバウンドな計算（純粋な計算処理）では、これによりコア数に比例した劇的なパフォーマンス向上が得られます。

---

## 5.7 まとめ

本章では、Rustで安全に並行・並列コードを書くための、実践的で重要な3つのアプローチを学びました。

1.  **共有メモリ (`Arc<Mutex<T>>`):** 複数のスレッド間で状態を共有するための、基本的で強力なパターン。CSの相互排他と参照カウントに基づきます。
2.  **メッセージパッシング (`mpsc::channel`):** ロックを避け、所有権の移動によって通信するクリーンな設計。CSのアクターモデルやCSPに基づきます。
3.  **データ並列 (`rayon`):** CPUバウンドな問題を、最小限のコード変更で劇的に高速化する手段。CSのデータ並列処理とワークスティーリングに基づきます。

そして、これら全てを支えているのが、コンパイル時にデータ競合を防ぐ**`Send`と`Sync`トレイト**です。これにより、Rust開発者は実行時エラーの恐怖から解放され、自信を持ってマルチコアの性能を最大限に引き出すことができるのです。